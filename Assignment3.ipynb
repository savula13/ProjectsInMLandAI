{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXFmHwHMmYZ6s6LZ9YvkZL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/savula13/ProjectsInMLandAI/blob/main/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 3\n",
        "Saipranav Avula"
      ],
      "metadata": {
        "id": "w8UZF1o497kR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBdJJopYNLQS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "import tensorflow.keras as keras\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from sklearn import model_selection as ms\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Research\n",
        "\n",
        "For implementing a 2-layer neural network, I used Tensorflow and I specifically used the Keras framework.\n",
        "With Keras, I learned how to instantiate a model with a set number of input nodes using the Model class. \n",
        "From the Keras documentation, I learned how to use the Sequential class to manually add hidden\n",
        "and output layers to the insantiated model. In this documentation, it also details how to set the activation\n",
        "functions for each layer. \n",
        "\n",
        "The Functional API for Keras allows a user to create more complex models than the Sequential class, which is not\n",
        "as applicable for this particular assignment, but it has functionality to obtain model summaries and model visualizations\n",
        "which are useful in evaluating models.\n",
        "\n",
        "Keras also has a class for hyperparameter tuning. I used the documentation for the Tuner class to learn about how different\n",
        "methods such as RandomSearch, Hyperband, and Bayesian Optimization can be used to find the optimal hyperparameters such as \n",
        "the number of nodes in the hidden layers, the number of hidden layers, learning rate, momentum, etc.\n",
        "\n",
        "\n",
        "\n",
        "## Links\n",
        "https://keras.io/guides/functional_api/\n",
        "\n",
        "https://keras.io/api/models/sequential/\n",
        "\n",
        "https://keras.io/api/models/model/\n",
        "\n",
        "https://keras.io/getting_started/intro_to_keras_for_engineers/\n",
        "\n",
        "https://keras.io/api/keras_tuner/tuners/random/\n",
        "\n",
        "https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
        "\n",
        "https://towardsdatascience.com/the-art-of-hyperparameter-tuning-in-deep-neural-nets-by-example-685cb5429a38\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2021/05/tuning-the-hyperparameters-and-layers-of-neural-network-deep-learning/\n",
        "\n"
      ],
      "metadata": {
        "id": "BpFkJOLT8vI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2\n",
        "## 1. Exploratory Data Analysis\n",
        "The dataset I am using is based on Stellar Classification which uses the spectral data of stars to categorize them into different categories.\n",
        "Specifically the raw data has been processed to use Absolute Magnitude and B-V Color Index to identify Giants and Dwarfs.\n",
        "\n",
        "https://www.kaggle.com/datasets/vinesmsuic/star-categorization-giants-and-dwarfs"
      ],
      "metadata": {
        "id": "pL-0b8H08x_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./Star39552_balanced.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7vALOrWINW36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop([\"SpType\"], axis = 1, inplace = True)\n",
        "rows, cols = df.shape\n",
        "print(\"There are {} rows\".format(rows))\n",
        "print(\"There are {} columns\".format(cols))"
      ],
      "metadata": {
        "id": "KT_92Ufg80XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ROLV2-g0812n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data has already gone through preprocessing so it is already balanced."
      ],
      "metadata": {
        "id": "JwMrbZC-85m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.TargetClass.value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "m9ZtvTtb84Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sn.pairplot(df, hue = \"TargetClass\")"
      ],
      "metadata": {
        "id": "2XIMNJNP89gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 0:cols-1]\n",
        "Y = df.iloc[:, cols-1]\n",
        "Y.head()"
      ],
      "metadata": {
        "id": "IlhtNHFI8_UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Train Dev Test Split"
      ],
      "metadata": {
        "id": "jmsmJxiM9Ack"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, Y_train, Y_temp = ms.train_test_split(X, Y, test_size = 0.3, random_state= 42)\n",
        "X_temp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "pGHtbaoU9CK8",
        "outputId": "6bf716e6-bcb8-4afd-8ec0-29d8c2aa5887"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d1c703c730b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, X_dev, Y_test, Y_dev = ms.train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "SLtZv4e09D8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test.shape"
      ],
      "metadata": {
        "id": "bB0_0dMe9FSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Forward Propogation\n",
        "\n",
        "For the forward propogation, I am using the relu activation function for the first 2 layers of the model (input and first).\n",
        "\n",
        "Since it is linear for values greater than 0, the relu is a common and good choice of activation functon. \n",
        "and the sigmoid activation is used for the output layer so that the outputs are between 0 and 1. \n",
        "\n",
        "In this case the number of layer nodes is manually set. Hyperparameter tuning is implemented later to determine the optimal number of layer nodes."
      ],
      "metadata": {
        "id": "diLpnyQ39LbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_model = tf.keras.Sequential()\n",
        "init_model.add(Dense(12, input_shape=(cols-1,), activation='relu'))\n",
        "init_model.add(Dense(6, activation='relu'))\n",
        "init_model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "Ve_wtROf9GaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 & 5. Cost Function and Gradient Descent\n",
        "\n",
        "Gradient descent is implemented using binary cross-entropy as the loss function. Since the target variable (giant star or dwarf star) is binary, \n",
        "binary cross-entropy is an ideal choice since it is usually used for binary classifcation problems. This includes optimizing the cost function over the layers as well\n",
        "\n",
        "The Adam optimizer is used, which uses the past gradients to calculate the current gradient and is commonly used in training neural nets. Since it \n",
        "has built in tuning it is a good option to choose as optimizer."
      ],
      "metadata": {
        "id": "Ah2cTWE89Nm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "G9ehxOBz9aSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, the neural network is trained on teh training data. Then it is validated on the dev set."
      ],
      "metadata": {
        "id": "KHDlO31q9bUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = tf.convert_to_tensor(X_train)\n",
        "Yt = tf.convert_to_tensor(Y_train)\n",
        "init_model.fit(Xt, Yt, epochs = 10, batch_size=500)\n",
        "init_model.fit(X_train, Y_train, epochs= 10, validation_data=(X_dev, Y_dev))"
      ],
      "metadata": {
        "id": "WEjrmlMJ9dnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the neural network is trained and validated initially, then the predictions made by the model are evaluated using the test set."
      ],
      "metadata": {
        "id": "20qb4LNe9eud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_temp = init_model.evaluate(X_test, Y_test)\n",
        "\n",
        "print(\"The accuracy with this initial neural network configuration is {}\".format(acc_temp[1]))"
      ],
      "metadata": {
        "id": "Oc-OJ03K9hI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3\n",
        "\n",
        "Now that the neural network has been initialized, the optimal hyperparameters can be found using RandomSearch. Keras has a Tuner\n",
        "class that makes it relatively simple to implement RandomSearch with given constraints of hyperparameters.\n",
        "\n",
        "I chose this method to choose the optimal hyperparameters because it is more efficient and generally as effective as GridSearch.\n",
        "\n",
        "I also chose the Adam optimizer as in other machine learning research, Adam has proven to be an effective optimizer that tunes itself.\n",
        "\n",
        "The varied hyperparameters are:\n",
        "\n",
        "1. Nodes in First Hidden Layer\n",
        "2. Nodes in Second Hidden Layer\n",
        "3. Learning rate\n",
        "\n",
        "I did not use regularization because as seen in the inital runs,\n",
        "the accuracy on the training sets is similar to when it is validated using the dev sets (70% accuacy on training vs 83% accuracy on dev).\n",
        "Therefore, there is no concern that the model is overfitting."
      ],
      "metadata": {
        "id": "TTVXO2Dz9j49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    \n",
        "    first_layer = hp.Int(name = 'first_layer', min_value = 16, max_value = 128, step = 16)\n",
        "    second_layer = hp.Int(name = 'second_layer', min_value = 16, max_value = 64, step = 16)\n",
        "\n",
        "    #Forward Propogation \n",
        "\n",
        "    #Creating neural network layers with dropouts\n",
        "    model = tf.keras.Sequential()\n",
        "    #input and first hidden layer\n",
        "    model.add(Dense(units = first_layer, input_shape=(5,), activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "    #second hidden layer\n",
        "    model.add(Dense(units = second_layer, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "    #output layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    #choices for learning rate \n",
        "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
        "\n",
        "    #Cost Function and Gradient Descent Implementation\n",
        "    #configuring model with choices from above\n",
        "    model.compile(loss='binary_crossentropy', optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "RwjLH0bu9kx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the RandomSearch and model are configured, the model is fit on the training data and then validated using the dev set. The RandomSearch tunes the parameters\n",
        "after every iteration of the validation on the dev set."
      ],
      "metadata": {
        "id": "dKRpwTDg9m6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(build_model, objective = 'val_accuracy', max_trials = 5, directory = 'temp2',\n",
        "project_name = 'random_search') \n",
        "\n",
        "#fitting model on training data, validating using dev set, and tuning after each iteration\n",
        "tuner.search(X_train, Y_train, epochs = 10, validation_data = (X_dev, Y_dev))"
      ],
      "metadata": {
        "id": "rzmn9KNc9pYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the Random Search is done, then the best hyperparameters for the model are found."
      ],
      "metadata": {
        "id": "tV48d8xN9tP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#returing best hyperparameters to use in final model\n",
        "best_model = tuner.get_best_models(1)[0]\n",
        "best_hyperparameters = tuner.get_best_hyperparameters(1)[0] \n",
        "print(f\"\"\"\n",
        "The hyperparameter search has been completed. \n",
        "The optimal number of layers in the first densely-connected\n",
        "layer is {best_hyperparameters.get('first_layer')}. The optimal number of layers in the second densely-connected layer is {best_hyperparameters.get('second_layer')}. \n",
        "The optimal learning rate for the optimizer is {best_hyperparameters.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "o_vS-foU9tvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A final neural network model is built with the best hyperparameters from the random search. It is then fit on the training set and validated using the dev set."
      ],
      "metadata": {
        "id": "o6z7_U8B9vpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = tuner.hypermodel.build(best_hyperparameters)\n",
        "\n",
        "model.fit(X_train, Y_train, epochs= 10, validation_data=(X_dev, Y_dev))\n"
      ],
      "metadata": {
        "id": "EyxszdVv9x1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the best model is trained and validated, it is evauluated using the test data."
      ],
      "metadata": {
        "id": "9fB2wvX69zmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = model.evaluate(X_test, Y_test)\n",
        "\n",
        "print(\"The accuracy of the neural network with the optimal hyperparameters when evaluated on the test set is {}\".format(acc))\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "KY9gMltb90pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4\n",
        "\n",
        "I am creating a logistic regression model to compare its performance with the neural network peformance. Logistic regression is ideal for binary classification and we have used it for previous binary classifcaiton problems"
      ],
      "metadata": {
        "id": "maEqImrc91_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "1Myd1W4E92-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = lr_model.predict(X_test)\n",
        "\n",
        "test_accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "\n",
        "print(\"The accuracy of the logistic regression model when evaluated on the test set is {}\".format(test_accuracy))"
      ],
      "metadata": {
        "id": "rwVIzYWG94Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison\n",
        "\n",
        "The accuracy of the nerual network model is .8756 87.6%$ (in my testing).\n",
        "\n",
        "The accuracy of the logistic regression model is .877 ~ 87.7% (in my testing).\n",
        "\n",
        "Therefore, the models are achieving the same accuracy on the same training and test sets.\n",
        "One reason that they have the same performance is that there is not a large number of features/columns\n",
        "in the dataset. Neural networks tend to have substantial improvement over other models when using unstructured\n",
        "data or data with many input features. Therefore, it makes sense that a simpler model such as Logistic Regression is\n",
        "able to achieve very similar accuracy. \n",
        "\n",
        "Another factor could be that the neural network I used had 2 hidden layers. If a network with more layers was chosen it could've\n",
        "led to a more substantial improvement over the Logistic Regression."
      ],
      "metadata": {
        "id": "awD_lkDy95aD"
      }
    }
  ]
}